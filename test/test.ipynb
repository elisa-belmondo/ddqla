{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'agent'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mddqla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01magent\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Agent\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Input, Dense\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n",
      "File \u001B[0;32m~/PycharmProjects/ddqla/venv/lib/python3.10/site-packages/ddqla/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01magent\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Agent\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'agent'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ddqla.agents import BaseAgent\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "\n",
    "class Imex(BaseAgent):\n",
    "    __ACTIONS = 4\n",
    "    __STARTUP_ENVIRONMENT = np.asarray([7, 4, 1, 4], dtype=np.float32)\n",
    "    __MATRIX_SIDE_DIM = 9\n",
    "    __DENSE_DIM = 2048\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            Imex.__ACTIONS,\n",
    "            Imex.__STARTUP_ENVIRONMENT,\n",
    "            fit_each_n_steps=600,\n",
    "            cumulative_rewards_max_length=600\n",
    "        )\n",
    "\n",
    "    def _get_model(self, state_features):\n",
    "        inputs = Input(shape=(state_features,))\n",
    "        dense = Dense(Imex.__DENSE_DIM, activation='swish')(inputs)\n",
    "        dense = Dense(Imex.__DENSE_DIM, activation='swish')(dense)\n",
    "        outputs = Dense(Imex.__ACTIONS, activation='linear')(dense)\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=Adam(), loss=MeanSquaredError())\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def reset_state(self):\n",
    "        self._state = Imex.__STARTUP_ENVIRONMENT\n",
    "\n",
    "    def _get_reward(self, action, environment):\n",
    "        self.environment_log.append(environment)\n",
    "        reward = -1\n",
    "        new_pos = np.asarray([self._state[0], self._state[1]])\n",
    "        match action:\n",
    "            case 0:  # up\n",
    "                new_pos[1] -= 1\n",
    "            case 1:  # right\n",
    "                new_pos[0] += 1\n",
    "            case 2:  # down\n",
    "                new_pos[1] += 1\n",
    "            case 3:  # left\n",
    "                new_pos[0] -= 1\n",
    "        if 0 <= new_pos[0] < Imex.__MATRIX_SIDE_DIM and 0 <= new_pos[1] < Imex.__MATRIX_SIDE_DIM:\n",
    "            environment[0] = new_pos[0]\n",
    "            environment[1] = new_pos[1]\n",
    "            self._state[0] = new_pos[0]\n",
    "            self._state[1] = new_pos[1]\n",
    "        if new_pos[0] == self._state[2] and new_pos[1] == self._state[3]:\n",
    "            reward = 6\n",
    "            self.reset_state()\n",
    "        return reward\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T15:57:24.073396Z",
     "start_time": "2023-08-01T15:57:23.775330Z"
    }
   },
   "id": "aa9d6f6aff04975"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imex = Imex()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T15:57:24.073004Z"
    }
   },
   "id": "768a7e9b7a23b046"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for step in range(0, 20000):\n",
    "    imex.step()\n",
    "    if step % 700 == 0 and imex.is_memory_ready():\n",
    "        rewards = imex.test(600)\n",
    "        cum_rewards = imex.get_last_cumulative_rewards()\n",
    "        print('#', step, '  CR: ', np.sum(cum_rewards), '  R: ', rewards)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T15:57:24.076701Z",
     "start_time": "2023-08-01T15:57:24.075092Z"
    }
   },
   "id": "a64bc03deb433fac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imex.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-01T15:57:24.076474Z"
    }
   },
   "id": "1f7009d34f43414"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "807c250521ca4b1d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
